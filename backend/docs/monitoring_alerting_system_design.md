# ChronoRetrace ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿå®Œå–„è®¾è®¡æ–¹æ¡ˆ

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 è®¾è®¡ç›®æ ‡
åŸºäºå½“å‰é¡¹ç›®å·²æœ‰çš„ç›‘æ§åŸºç¡€è®¾æ–½ï¼ˆPrometheusã€Grafanaã€Alertmanagerï¼‰ï¼Œå®Œå–„ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿï¼Œå®ç°ï¼š
- å…¨æ–¹ä½çš„ç³»ç»Ÿç›‘æ§è¦†ç›–
- æ™ºèƒ½åŒ–çš„å‘Šè­¦æœºåˆ¶
- å¯è§†åŒ–çš„ç›‘æ§ä»ªè¡¨æ¿
- è‡ªåŠ¨åŒ–çš„æ•…éšœå¤„ç†
- å®Œå–„çš„ç›‘æ§æ•°æ®åˆ†æ

### 1.2 å½“å‰çŠ¶æ€åˆ†æ
**å·²æœ‰é…ç½®æ–‡ä»¶ï¼š**
- âœ… Prometheus é…ç½®æ–‡ä»¶ (`backend/config/prometheus.yml`)
- âœ… Grafana ä»ªè¡¨æ¿é…ç½® (`backend/config/grafana-dashboard.json`)
- âœ… å‘Šè­¦è§„åˆ™é…ç½® (`backend/config/alert-rules.yml`)
- âœ… åŸºç¡€çš„å¥åº·æ£€æŸ¥è„šæœ¬ (`backend/scripts/monitoring_health_check.py`)
- âœ… Docker Compose ç›‘æ§æœåŠ¡å®šä¹‰

**éœ€è¦éƒ¨ç½²å’Œå®Œå–„çš„éƒ¨åˆ†ï¼š**
- ğŸ”§ ä¿®å¤ç›‘æ§æœåŠ¡éƒ¨ç½²é…ç½®
- ğŸ”§ åˆ›å»ºæ­£ç¡®çš„ç›®å½•ç»“æ„
- ğŸ”§ éƒ¨ç½²Prometheuså’ŒGrafanaæœåŠ¡
- ğŸ”„ åº”ç”¨å±‚æŒ‡æ ‡æ”¶é›†å¢å¼º
- ğŸ”„ æ™ºèƒ½å‘Šè­¦ç­–ç•¥ä¼˜åŒ–
- ğŸ”„ ç›‘æ§æ•°æ®åˆ†æå’Œé¢„æµ‹
- ğŸ”„ è‡ªåŠ¨åŒ–æ•…éšœæ¢å¤
- ğŸ”„ ç›‘æ§ç³»ç»Ÿçš„é«˜å¯ç”¨æ€§

## 2. ç³»ç»Ÿæ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æ¶æ„å›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ChronoRetrace ç›‘æ§ç³»ç»Ÿ                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®æ”¶é›†å±‚ (Data Collection Layer)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ App Metrics â”‚ â”‚ Infra       â”‚ â”‚ Business    â”‚ â”‚ External    â”‚ â”‚
â”‚  â”‚ - APIæŒ‡æ ‡   â”‚ â”‚ Metrics     â”‚ â”‚ Metrics     â”‚ â”‚ Monitoring  â”‚ â”‚
â”‚  â”‚ - æ€§èƒ½æŒ‡æ ‡  â”‚ â”‚ - ç³»ç»Ÿèµ„æº  â”‚ â”‚ - ä¸šåŠ¡æŒ‡æ ‡  â”‚ â”‚ - ç¬¬ä¸‰æ–¹API â”‚ â”‚
â”‚  â”‚ - é”™è¯¯æ—¥å¿—  â”‚ â”‚ - æ•°æ®åº“    â”‚ â”‚ - ç”¨æˆ·è¡Œä¸º  â”‚ â”‚ - æ•°æ®æº    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å­˜å‚¨å±‚ (Data Storage Layer)                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Prometheus  â”‚ â”‚ InfluxDB    â”‚ â”‚ Elasticsearchâ”‚ â”‚ PostgreSQL  â”‚ â”‚
â”‚  â”‚ - æ—¶åºæ•°æ®  â”‚ â”‚ - é«˜é¢‘æ•°æ®  â”‚ â”‚ - æ—¥å¿—æ•°æ®   â”‚ â”‚ - é…ç½®æ•°æ®  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ•°æ®å¤„ç†å±‚ (Data Processing Layer)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Alert       â”‚ â”‚ Anomaly     â”‚ â”‚ Trend       â”‚ â”‚ Correlation â”‚ â”‚
â”‚  â”‚ Engine      â”‚ â”‚ Detection   â”‚ â”‚ Analysis    â”‚ â”‚ Analysis    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å±•ç¤ºå±‚ (Presentation Layer)                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Grafana     â”‚ â”‚ Custom      â”‚ â”‚ Mobile      â”‚ â”‚ API         â”‚ â”‚
â”‚  â”‚ Dashboards  â”‚ â”‚ Web UI      â”‚ â”‚ App         â”‚ â”‚ Endpoints   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  é€šçŸ¥å±‚ (Notification Layer)                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Email       â”‚ â”‚ Slack/Teams â”‚ â”‚ SMS         â”‚ â”‚ Webhook     â”‚ â”‚
â”‚  â”‚ Alerts      â”‚ â”‚ Integration â”‚ â”‚ Alerts      â”‚ â”‚ Integration â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 æ ¸å¿ƒç»„ä»¶è®¾è®¡

#### 2.2.1 æŒ‡æ ‡æ”¶é›†å¢å¼ºå™¨ (Enhanced Metrics Collector)
```python
# æ–°å¢ç»„ä»¶ï¼šbackend/app/infrastructure/monitoring/metrics_collector.py
class EnhancedMetricsCollector:
    """å¢å¼ºçš„æŒ‡æ ‡æ”¶é›†å™¨"""

    # åº”ç”¨å±‚æŒ‡æ ‡
    - APIå“åº”æ—¶é—´åˆ†å¸ƒ
    - è¯·æ±‚æˆåŠŸç‡å’Œé”™è¯¯ç‡
    - å¹¶å‘ç”¨æˆ·æ•°
    - æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½
    - ç¼“å­˜å‘½ä¸­ç‡
    - WebSocketè¿æ¥æ•°

    # ä¸šåŠ¡æŒ‡æ ‡
    - ç”¨æˆ·æ´»è·ƒåº¦
    - æ•°æ®æ›´æ–°é¢‘ç‡
    - è‚¡ç¥¨æŸ¥è¯¢çƒ­åº¦
    - å›æµ‹ä»»åŠ¡æ‰§è¡Œæƒ…å†µ
    - æ•°æ®æºå¯ç”¨æ€§
```

#### 2.2.2 æ™ºèƒ½å‘Šè­¦å¼•æ“ (Intelligent Alert Engine)
```python
# æ–°å¢ç»„ä»¶ï¼šbackend/app/infrastructure/monitoring/alert_engine.py
class IntelligentAlertEngine:
    """æ™ºèƒ½å‘Šè­¦å¼•æ“"""

    # åŠ¨æ€é˜ˆå€¼è°ƒæ•´
    - åŸºäºå†å²æ•°æ®çš„è‡ªé€‚åº”é˜ˆå€¼
    - æ—¶é—´æ®µç›¸å…³çš„é˜ˆå€¼ç­–ç•¥
    - ä¸šåŠ¡åœºæ™¯ç›¸å…³çš„å‘Šè­¦è§„åˆ™

    # å‘Šè­¦èšåˆå’Œå»é‡
    - ç›¸å…³å‘Šè­¦çš„æ™ºèƒ½èšåˆ
    - é‡å¤å‘Šè­¦çš„è‡ªåŠ¨å»é‡
    - å‘Šè­¦é£æš´çš„é˜²æŠ¤æœºåˆ¶

    # å‘Šè­¦ä¼˜å…ˆçº§ç®¡ç†
    - åŸºäºå½±å“èŒƒå›´çš„ä¼˜å…ˆçº§
    - ä¸šåŠ¡é‡è¦æ€§çš„æƒé‡è®¡ç®—
    - è‡ªåŠ¨å‡çº§æœºåˆ¶
```

#### 2.2.3 å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ (Anomaly Detection System)
```python
# æ–°å¢ç»„ä»¶ï¼šbackend/app/infrastructure/monitoring/anomaly_detector.py
class AnomalyDetector:
    """å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ"""

    # ç»Ÿè®¡å­¦æ–¹æ³•
    - 3-sigmaè§„åˆ™æ£€æµ‹
    - ç§»åŠ¨å¹³å‡çº¿åå·®
    - å­£èŠ‚æ€§è¶‹åŠ¿åˆ†æ

    # æœºå™¨å­¦ä¹ æ–¹æ³•
    - Isolation Forest
    - LSTMæ—¶åºé¢„æµ‹
    - èšç±»åˆ†æ

    # ä¸šåŠ¡è§„åˆ™æ£€æµ‹
    - è‡ªå®šä¹‰ä¸šåŠ¡è§„åˆ™
    - é˜ˆå€¼ç»„åˆæ£€æµ‹
    - æ¨¡å¼åŒ¹é…
```

## 3. è¯¦ç»†åŠŸèƒ½è®¾è®¡

### 3.1 åº”ç”¨å±‚ç›‘æ§å¢å¼º

#### 3.1.1 APIæ€§èƒ½ç›‘æ§
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/api_monitor.py

@dataclass
class APIMetrics:
    """APIæŒ‡æ ‡æ•°æ®ç±»"""
    endpoint: str
    method: str
    status_code: int
    response_time: float
    request_size: int
    response_size: int
    user_id: Optional[str]
    timestamp: datetime

class APIPerformanceMonitor:
    """APIæ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.redis_client = get_redis_client()

    async def track_request(self, request: Request, response: Response,
                          processing_time: float):
        """è·Ÿè¸ªAPIè¯·æ±‚"""
        metrics = APIMetrics(
            endpoint=request.url.path,
            method=request.method,
            status_code=response.status_code,
            response_time=processing_time,
            request_size=len(await request.body()) if hasattr(request, 'body') else 0,
            response_size=len(response.body) if hasattr(response, 'body') else 0,
            user_id=getattr(request.state, 'user_id', None),
            timestamp=datetime.utcnow()
        )

        # å‘é€åˆ°Prometheus
        await self._send_to_prometheus(metrics)

        # å­˜å‚¨è¯¦ç»†æ•°æ®åˆ°InfluxDB
        await self._store_detailed_metrics(metrics)

        # å®æ—¶å¼‚å¸¸æ£€æµ‹
        await self._check_anomalies(metrics)
```

#### 3.1.2 æ•°æ®åº“æ€§èƒ½ç›‘æ§
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/db_monitor.py

class DatabaseMonitor:
    """æ•°æ®åº“æ€§èƒ½ç›‘æ§"""

    def __init__(self):
        self.query_tracker = QueryTracker()
        self.connection_pool_monitor = ConnectionPoolMonitor()

    async def track_query(self, query: str, execution_time: float,
                         result_count: int):
        """è·Ÿè¸ªæ•°æ®åº“æŸ¥è¯¢"""

        # æŸ¥è¯¢æ€§èƒ½æŒ‡æ ‡
        query_metrics = {
            'query_hash': hashlib.sha256(query.encode()).hexdigest()[:16],
            'execution_time': execution_time,
            'result_count': result_count,
            'query_type': self._classify_query(query),
            'timestamp': time.time()
        }

        # æ…¢æŸ¥è¯¢æ£€æµ‹
        if execution_time > self.slow_query_threshold:
            await self._handle_slow_query(query, execution_time)

        # è¿æ¥æ± çŠ¶æ€ç›‘æ§
        pool_status = await self._get_pool_status()
        await self._update_pool_metrics(pool_status)
```

#### 3.1.3 ç¼“å­˜æ€§èƒ½ç›‘æ§
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/cache_monitor.py

class CacheMonitor:
    """ç¼“å­˜æ€§èƒ½ç›‘æ§"""

    def __init__(self):
        self.hit_rate_calculator = HitRateCalculator()
        self.memory_usage_tracker = MemoryUsageTracker()

    async def track_cache_operation(self, operation: str, key: str,
                                  hit: bool, response_time: float):
        """è·Ÿè¸ªç¼“å­˜æ“ä½œ"""

        cache_metrics = {
            'operation': operation,  # get, set, delete
            'cache_type': self._get_cache_type(key),
            'hit': hit,
            'response_time': response_time,
            'key_pattern': self._extract_key_pattern(key),
            'timestamp': time.time()
        }

        # æ›´æ–°å‘½ä¸­ç‡ç»Ÿè®¡
        await self._update_hit_rate_stats(cache_metrics)

        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory_usage = await self._get_memory_usage()
        await self._update_memory_metrics(memory_usage)
```

### 3.2 ä¸šåŠ¡æŒ‡æ ‡ç›‘æ§

#### 3.2.1 ç”¨æˆ·è¡Œä¸ºç›‘æ§
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/user_behavior_monitor.py

class UserBehaviorMonitor:
    """ç”¨æˆ·è¡Œä¸ºç›‘æ§"""

    def __init__(self):
        self.session_tracker = SessionTracker()
        self.feature_usage_tracker = FeatureUsageTracker()

    async def track_user_action(self, user_id: str, action: str,
                              context: Dict[str, Any]):
        """è·Ÿè¸ªç”¨æˆ·è¡Œä¸º"""

        behavior_data = {
            'user_id': user_id,
            'action': action,
            'context': context,
            'timestamp': datetime.utcnow(),
            'session_id': context.get('session_id'),
            'ip_address': context.get('ip_address'),
            'user_agent': context.get('user_agent')
        }

        # å®æ—¶ç”¨æˆ·æ´»è·ƒåº¦ç»Ÿè®¡
        await self._update_active_users(user_id)

        # åŠŸèƒ½ä½¿ç”¨æƒ…å†µç»Ÿè®¡
        await self._track_feature_usage(action, context)

        # ç”¨æˆ·è·¯å¾„åˆ†æ
        await self._analyze_user_journey(user_id, action)
```

#### 3.2.2 æ•°æ®æºç›‘æ§
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/data_source_monitor.py

class DataSourceMonitor:
    """æ•°æ®æºç›‘æ§"""

    def __init__(self):
        self.source_health_checker = SourceHealthChecker()
        self.data_quality_analyzer = DataQualityAnalyzer()

    async def monitor_data_source(self, source_name: str,
                                response_time: float,
                                data_quality: Dict[str, Any]):
        """ç›‘æ§æ•°æ®æºçŠ¶æ€"""

        source_metrics = {
            'source_name': source_name,
            'response_time': response_time,
            'availability': data_quality.get('availability', 0),
            'data_freshness': data_quality.get('freshness', 0),
            'error_rate': data_quality.get('error_rate', 0),
            'timestamp': time.time()
        }

        # æ•°æ®æºå¥åº·è¯„åˆ†
        health_score = await self._calculate_health_score(source_metrics)

        # æ•°æ®è´¨é‡å‘Šè­¦
        if health_score < self.health_threshold:
            await self._trigger_data_source_alert(source_name, health_score)
```

### 3.3 æ™ºèƒ½å‘Šè­¦ç³»ç»Ÿ

#### 3.3.1 åŠ¨æ€é˜ˆå€¼ç®¡ç†
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/dynamic_thresholds.py

class DynamicThresholdManager:
    """åŠ¨æ€é˜ˆå€¼ç®¡ç†å™¨"""

    def __init__(self):
        self.historical_data_analyzer = HistoricalDataAnalyzer()
        self.threshold_calculator = ThresholdCalculator()

    async def calculate_adaptive_threshold(self, metric_name: str,
                                         time_window: str = '7d') -> Dict[str, float]:
        """è®¡ç®—è‡ªé€‚åº”é˜ˆå€¼"""

        # è·å–å†å²æ•°æ®
        historical_data = await self._get_historical_data(metric_name, time_window)

        # æ—¶é—´æ¨¡å¼åˆ†æ
        time_patterns = await self._analyze_time_patterns(historical_data)

        # è®¡ç®—åŠ¨æ€é˜ˆå€¼
        thresholds = {
            'warning': self._calculate_percentile_threshold(historical_data, 0.95),
            'critical': self._calculate_percentile_threshold(historical_data, 0.99),
            'seasonal_adjustment': time_patterns.get('seasonal_factor', 1.0)
        }

        return thresholds

    async def update_alert_rules(self, metric_name: str, thresholds: Dict[str, float]):
        """æ›´æ–°å‘Šè­¦è§„åˆ™"""

        # æ›´æ–°Prometheuså‘Šè­¦è§„åˆ™
        await self._update_prometheus_rules(metric_name, thresholds)

        # æ›´æ–°Alertmanageré…ç½®
        await self._update_alertmanager_config(metric_name, thresholds)
```

#### 3.3.2 å‘Šè­¦èšåˆå’Œå»é‡
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/alert_aggregator.py

class AlertAggregator:
    """å‘Šè­¦èšåˆå™¨"""

    def __init__(self):
        self.correlation_engine = CorrelationEngine()
        self.deduplication_engine = DeduplicationEngine()

    async def process_alert(self, alert: Alert) -> Optional[AggregatedAlert]:
        """å¤„ç†å‘Šè­¦"""

        # å‘Šè­¦å»é‡
        if await self._is_duplicate_alert(alert):
            await self._update_duplicate_count(alert)
            return None

        # æŸ¥æ‰¾ç›¸å…³å‘Šè­¦
        related_alerts = await self._find_related_alerts(alert)

        # å‘Šè­¦èšåˆ
        if related_alerts:
            aggregated_alert = await self._aggregate_alerts(alert, related_alerts)
            return aggregated_alert

        return alert

    async def _find_related_alerts(self, alert: Alert) -> List[Alert]:
        """æŸ¥æ‰¾ç›¸å…³å‘Šè­¦"""

        # æ—¶é—´çª—å£å†…çš„å‘Šè­¦
        time_window_alerts = await self._get_alerts_in_time_window(
            alert.timestamp, timedelta(minutes=5)
        )

        # ç›¸å…³æ€§åˆ†æ
        related_alerts = []
        for candidate in time_window_alerts:
            correlation_score = await self._calculate_correlation(alert, candidate)
            if correlation_score > self.correlation_threshold:
                related_alerts.append(candidate)

        return related_alerts
```

#### 3.3.3 å‘Šè­¦å‡çº§æœºåˆ¶
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/alert_escalation.py

class AlertEscalationManager:
    """å‘Šè­¦å‡çº§ç®¡ç†å™¨"""

    def __init__(self):
        self.escalation_rules = EscalationRules()
        self.notification_manager = NotificationManager()

    async def process_alert_escalation(self, alert: Alert):
        """å¤„ç†å‘Šè­¦å‡çº§"""

        # è·å–å‡çº§è§„åˆ™
        escalation_rule = await self._get_escalation_rule(alert)

        # æ£€æŸ¥å‡çº§æ¡ä»¶
        if await self._should_escalate(alert, escalation_rule):

            # å‡çº§å‘Šè­¦çº§åˆ«
            escalated_alert = await self._escalate_alert(alert, escalation_rule)

            # å‘é€å‡çº§é€šçŸ¥
            await self._send_escalation_notification(escalated_alert)

            # è®°å½•å‡çº§å†å²
            await self._record_escalation_history(alert, escalated_alert)

    async def _should_escalate(self, alert: Alert, rule: EscalationRule) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥å‡çº§"""

        # æ—¶é—´æ¡ä»¶
        if alert.duration > rule.time_threshold:
            return True

        # å½±å“èŒƒå›´æ¡ä»¶
        if alert.affected_services > rule.service_threshold:
            return True

        # ä¸šåŠ¡å½±å“æ¡ä»¶
        if alert.business_impact_score > rule.business_threshold:
            return True

        return False
```

### 3.4 ç›‘æ§æ•°æ®åˆ†æ

#### 3.4.1 è¶‹åŠ¿åˆ†æå¼•æ“
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/trend_analyzer.py

class TrendAnalyzer:
    """è¶‹åŠ¿åˆ†æå¼•æ“"""

    def __init__(self):
        self.time_series_analyzer = TimeSeriesAnalyzer()
        self.forecasting_engine = ForecastingEngine()

    async def analyze_metric_trends(self, metric_name: str,
                                  time_range: str = '30d') -> TrendAnalysis:
        """åˆ†ææŒ‡æ ‡è¶‹åŠ¿"""

        # è·å–æ—¶åºæ•°æ®
        time_series_data = await self._get_time_series_data(metric_name, time_range)

        # è¶‹åŠ¿æ£€æµ‹
        trend_direction = await self._detect_trend_direction(time_series_data)
        trend_strength = await self._calculate_trend_strength(time_series_data)

        # å­£èŠ‚æ€§åˆ†æ
        seasonal_patterns = await self._analyze_seasonal_patterns(time_series_data)

        # å¼‚å¸¸ç‚¹æ£€æµ‹
        anomalies = await self._detect_anomalies(time_series_data)

        # é¢„æµ‹åˆ†æ
        forecast = await self._generate_forecast(time_series_data)

        return TrendAnalysis(
            metric_name=metric_name,
            trend_direction=trend_direction,
            trend_strength=trend_strength,
            seasonal_patterns=seasonal_patterns,
            anomalies=anomalies,
            forecast=forecast
        )
```

#### 3.4.2 å®¹é‡è§„åˆ’åˆ†æ
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/capacity_planner.py

class CapacityPlanner:
    """å®¹é‡è§„åˆ’åˆ†æå™¨"""

    def __init__(self):
        self.resource_analyzer = ResourceAnalyzer()
        self.growth_predictor = GrowthPredictor()

    async def analyze_capacity_requirements(self,
                                          resource_type: str,
                                          forecast_period: str = '90d') -> CapacityAnalysis:
        """åˆ†æå®¹é‡éœ€æ±‚"""

        # å½“å‰èµ„æºä½¿ç”¨æƒ…å†µ
        current_usage = await self._get_current_resource_usage(resource_type)

        # å†å²å¢é•¿è¶‹åŠ¿
        growth_trend = await self._analyze_growth_trend(resource_type)

        # é¢„æµ‹æœªæ¥éœ€æ±‚
        future_demand = await self._predict_future_demand(
            resource_type, forecast_period, growth_trend
        )

        # å®¹é‡å»ºè®®
        capacity_recommendations = await self._generate_capacity_recommendations(
            current_usage, future_demand
        )

        return CapacityAnalysis(
            resource_type=resource_type,
            current_usage=current_usage,
            growth_trend=growth_trend,
            future_demand=future_demand,
            recommendations=capacity_recommendations
        )
```

### 3.5 è‡ªåŠ¨åŒ–æ•…éšœå¤„ç†

#### 3.5.1 è‡ªåŠ¨æ¢å¤ç³»ç»Ÿ
```python
# æ–‡ä»¶ï¼šbackend/app/infrastructure/monitoring/auto_recovery.py

class AutoRecoverySystem:
    """è‡ªåŠ¨æ¢å¤ç³»ç»Ÿ"""

    def __init__(self):
        self.recovery_actions = RecoveryActions()
        self.safety_checker = SafetyChecker()

    async def handle_alert(self, alert: Alert):
        """å¤„ç†å‘Šè­¦å¹¶å°è¯•è‡ªåŠ¨æ¢å¤"""

        # è·å–æ¢å¤ç­–ç•¥
        recovery_strategy = await self._get_recovery_strategy(alert)

        if recovery_strategy and recovery_strategy.auto_recovery_enabled:

            # å®‰å…¨æ£€æŸ¥
            if await self._is_safe_to_recover(alert, recovery_strategy):

                # æ‰§è¡Œæ¢å¤æ“ä½œ
                recovery_result = await self._execute_recovery(
                    alert, recovery_strategy
                )

                # éªŒè¯æ¢å¤æ•ˆæœ
                if await self._verify_recovery(alert, recovery_result):
                    await self._log_successful_recovery(alert, recovery_result)
                else:
                    await self._escalate_failed_recovery(alert, recovery_result)

    async def _execute_recovery(self, alert: Alert,
                              strategy: RecoveryStrategy) -> RecoveryResult:
        """æ‰§è¡Œæ¢å¤æ“ä½œ"""

        recovery_actions = []

        for action in strategy.actions:
            try:
                if action.type == 'restart_service':
                    result = await self._restart_service(action.target)
                elif action.type == 'scale_up':
                    result = await self._scale_up_service(action.target, action.params)
                elif action.type == 'clear_cache':
                    result = await self._clear_cache(action.target)
                elif action.type == 'switch_datasource':
                    result = await self._switch_datasource(action.target, action.params)

                recovery_actions.append(result)

            except Exception as e:
                recovery_actions.append(RecoveryActionResult(
                    action=action,
                    success=False,
                    error=str(e)
                ))

        return RecoveryResult(
            alert=alert,
            strategy=strategy,
            actions=recovery_actions,
            timestamp=datetime.utcnow()
        )
```

## 4. å®æ–½è®¡åˆ’

### 4.1 ç¬¬ä¸€é˜¶æ®µï¼šåŸºç¡€è®¾æ–½å®Œå–„ï¼ˆ2å‘¨ï¼‰

#### 4.1.1 ç›‘æ§æ•°æ®å­˜å‚¨ä¼˜åŒ–
- **ä»»åŠ¡1.1**: éƒ¨ç½²InfluxDBç”¨äºé«˜é¢‘æ—¶åºæ•°æ®å­˜å‚¨
- **ä»»åŠ¡1.2**: é…ç½®Elasticsearchç”¨äºæ—¥å¿—èšåˆå’Œæœç´¢
- **ä»»åŠ¡1.3**: ä¼˜åŒ–Prometheuså­˜å‚¨é…ç½®å’Œæ•°æ®ä¿ç•™ç­–ç•¥
- **ä»»åŠ¡1.4**: å®ç°ç›‘æ§æ•°æ®çš„å¤‡ä»½å’Œæ¢å¤æœºåˆ¶

#### 4.1.2 æŒ‡æ ‡æ”¶é›†å¢å¼º
- **ä»»åŠ¡1.5**: å®ç°åº”ç”¨å±‚æ€§èƒ½æŒ‡æ ‡æ”¶é›†
- **ä»»åŠ¡1.6**: å¢å¼ºæ•°æ®åº“æ€§èƒ½ç›‘æ§
- **ä»»åŠ¡1.7**: å®Œå–„ç¼“å­˜ç³»ç»Ÿç›‘æ§
- **ä»»åŠ¡1.8**: æ·»åŠ ä¸šåŠ¡æŒ‡æ ‡æ”¶é›†

### 4.2 ç¬¬äºŒé˜¶æ®µï¼šæ™ºèƒ½å‘Šè­¦ç³»ç»Ÿï¼ˆ3å‘¨ï¼‰

#### 4.2.1 åŠ¨æ€é˜ˆå€¼ç³»ç»Ÿ
- **ä»»åŠ¡2.1**: å®ç°å†å²æ•°æ®åˆ†æå¼•æ“
- **ä»»åŠ¡2.2**: å¼€å‘è‡ªé€‚åº”é˜ˆå€¼è®¡ç®—ç®—æ³•
- **ä»»åŠ¡2.3**: é›†æˆæ—¶é—´æ¨¡å¼è¯†åˆ«
- **ä»»åŠ¡2.4**: å®ç°é˜ˆå€¼è‡ªåŠ¨æ›´æ–°æœºåˆ¶

#### 4.2.2 å‘Šè­¦èšåˆå’Œå»é‡
- **ä»»åŠ¡2.5**: å¼€å‘å‘Šè­¦ç›¸å…³æ€§åˆ†æå¼•æ“
- **ä»»åŠ¡2.6**: å®ç°å‘Šè­¦å»é‡æœºåˆ¶
- **ä»»åŠ¡2.7**: æ„å»ºå‘Šè­¦èšåˆç³»ç»Ÿ
- **ä»»åŠ¡2.8**: å®ç°å‘Šè­¦å‡çº§æœºåˆ¶

### 4.3 ç¬¬ä¸‰é˜¶æ®µï¼šé«˜çº§åˆ†æåŠŸèƒ½ï¼ˆ3å‘¨ï¼‰

#### 4.3.1 å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ
- **ä»»åŠ¡3.1**: å®ç°ç»Ÿè®¡å­¦å¼‚å¸¸æ£€æµ‹ç®—æ³•
- **ä»»åŠ¡3.2**: é›†æˆæœºå™¨å­¦ä¹ å¼‚å¸¸æ£€æµ‹æ¨¡å‹
- **ä»»åŠ¡3.3**: å¼€å‘ä¸šåŠ¡è§„åˆ™æ£€æµ‹å¼•æ“
- **ä»»åŠ¡3.4**: å®ç°å¼‚å¸¸æ£€æµ‹ç»“æœå¯è§†åŒ–

#### 4.3.2 è¶‹åŠ¿åˆ†æå’Œé¢„æµ‹
- **ä»»åŠ¡3.5**: å¼€å‘æ—¶åºæ•°æ®è¶‹åŠ¿åˆ†æ
- **ä»»åŠ¡3.6**: å®ç°å®¹é‡è§„åˆ’åˆ†æ
- **ä»»åŠ¡3.7**: æ„å»ºæ€§èƒ½é¢„æµ‹æ¨¡å‹
- **ä»»åŠ¡3.8**: å®ç°é¢„æµ‹ç»“æœå±•ç¤º

### 4.4 ç¬¬å››é˜¶æ®µï¼šè‡ªåŠ¨åŒ–å’Œé›†æˆï¼ˆ2å‘¨ï¼‰

#### 4.4.1 è‡ªåŠ¨æ¢å¤ç³»ç»Ÿ
- **ä»»åŠ¡4.1**: å®ç°è‡ªåŠ¨æ¢å¤ç­–ç•¥å¼•æ“
- **ä»»åŠ¡4.2**: å¼€å‘å®‰å…¨æ£€æŸ¥æœºåˆ¶
- **ä»»åŠ¡4.3**: æ„å»ºæ¢å¤æ“ä½œæ‰§è¡Œå™¨
- **ä»»åŠ¡4.4**: å®ç°æ¢å¤æ•ˆæœéªŒè¯

#### 4.4.2 ç³»ç»Ÿé›†æˆå’Œä¼˜åŒ–
- **ä»»åŠ¡4.5**: å®Œå–„ç›‘æ§ç³»ç»Ÿé«˜å¯ç”¨é…ç½®
- **ä»»åŠ¡4.6**: ä¼˜åŒ–ç›‘æ§ç³»ç»Ÿæ€§èƒ½
- **ä»»åŠ¡4.7**: å®ç°ç›‘æ§é…ç½®ç®¡ç†
- **ä»»åŠ¡4.8**: å®Œå–„æ–‡æ¡£å’ŒåŸ¹è®­ææ–™

## 5. æŠ€æœ¯å®ç°ç»†èŠ‚

### 5.1 æ–°å¢ä¾èµ–åŒ…
```python
# requirements-monitoring.txt
influxdb-client==1.38.0
elasticsearch==8.10.0
scikit-learn==1.3.0
pandas==2.1.0
numpy==1.24.0
scipy==1.11.0
statsmodels==0.14.0
tensorflow==2.13.0  # ç”¨äºLSTMå¼‚å¸¸æ£€æµ‹
prometheus-client==0.17.1
grafana-api==1.0.3
```

### 5.2 é…ç½®æ–‡ä»¶ç»“æ„
```yaml
# config/monitoring.yml
monitoring:
  # æ•°æ®å­˜å‚¨é…ç½®
  storage:
    prometheus:
      retention: "30d"
      storage_size: "10GB"
    influxdb:
      url: "http://influxdb:8086"
      database: "chronoretrace_metrics"
      retention_policy: "90d"
    elasticsearch:
      hosts: ["elasticsearch:9200"]
      index_pattern: "chronoretrace-logs-*"

  # å‘Šè­¦é…ç½®
  alerting:
    dynamic_thresholds:
      enabled: true
      update_interval: "1h"
      lookback_period: "7d"
    aggregation:
      enabled: true
      correlation_threshold: 0.8
      time_window: "5m"
    escalation:
      enabled: true
      escalation_rules:
        - name: "critical_service_down"
          conditions:
            - duration: "5m"
            - severity: "critical"
          actions:
            - notify: ["oncall", "management"]
            - auto_recovery: true

  # å¼‚å¸¸æ£€æµ‹é…ç½®
  anomaly_detection:
    methods:
      - name: "statistical"
        enabled: true
        sensitivity: 0.95
      - name: "ml_isolation_forest"
        enabled: true
        contamination: 0.1
      - name: "lstm_prediction"
        enabled: false  # éœ€è¦è®­ç»ƒæ•°æ®

  # è‡ªåŠ¨æ¢å¤é…ç½®
  auto_recovery:
    enabled: true
    safety_checks:
      - max_recovery_attempts: 3
      - cooldown_period: "10m"
      - require_approval_for: ["production"]
    recovery_actions:
      - name: "restart_service"
        timeout: "30s"
        rollback_on_failure: true
      - name: "scale_up"
        max_instances: 10
        scale_factor: 1.5
```

### 5.3 æ•°æ®åº“æ¨¡å¼è®¾è®¡
```sql
-- ç›‘æ§é…ç½®è¡¨
CREATE TABLE monitoring_configs (
    id SERIAL PRIMARY KEY,
    config_name VARCHAR(100) NOT NULL,
    config_type VARCHAR(50) NOT NULL,
    config_data JSONB NOT NULL,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å‘Šè­¦å†å²è¡¨
CREATE TABLE alert_history (
    id SERIAL PRIMARY KEY,
    alert_id VARCHAR(100) NOT NULL,
    alert_name VARCHAR(200) NOT NULL,
    severity VARCHAR(20) NOT NULL,
    status VARCHAR(20) NOT NULL,
    started_at TIMESTAMP NOT NULL,
    resolved_at TIMESTAMP,
    duration_seconds INTEGER,
    affected_services TEXT[],
    recovery_actions JSONB,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å¼‚å¸¸æ£€æµ‹ç»“æœè¡¨
CREATE TABLE anomaly_detections (
    id SERIAL PRIMARY KEY,
    metric_name VARCHAR(100) NOT NULL,
    detection_method VARCHAR(50) NOT NULL,
    anomaly_score FLOAT NOT NULL,
    threshold FLOAT NOT NULL,
    detected_at TIMESTAMP NOT NULL,
    context_data JSONB,
    is_confirmed BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- å®¹é‡è§„åˆ’è¡¨
CREATE TABLE capacity_plans (
    id SERIAL PRIMARY KEY,
    resource_type VARCHAR(50) NOT NULL,
    current_usage JSONB NOT NULL,
    predicted_usage JSONB NOT NULL,
    recommendations JSONB NOT NULL,
    forecast_period VARCHAR(20) NOT NULL,
    confidence_score FLOAT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## 6. ç›‘æ§æŒ‡æ ‡å®šä¹‰

### 6.1 åº”ç”¨å±‚æŒ‡æ ‡
```python
# å…³é”®æŒ‡æ ‡å®šä¹‰
APPLICATION_METRICS = {
    # APIæ€§èƒ½æŒ‡æ ‡
    'api_request_duration_seconds': {
        'type': 'histogram',
        'description': 'APIè¯·æ±‚å“åº”æ—¶é—´åˆ†å¸ƒ',
        'labels': ['method', 'endpoint', 'status_code']
    },
    'api_request_total': {
        'type': 'counter',
        'description': 'APIè¯·æ±‚æ€»æ•°',
        'labels': ['method', 'endpoint', 'status_code']
    },
    'api_concurrent_requests': {
        'type': 'gauge',
        'description': 'å¹¶å‘è¯·æ±‚æ•°',
        'labels': ['endpoint']
    },

    # æ•°æ®åº“æŒ‡æ ‡
    'db_query_duration_seconds': {
        'type': 'histogram',
        'description': 'æ•°æ®åº“æŸ¥è¯¢æ—¶é—´',
        'labels': ['query_type', 'table']
    },
    'db_connection_pool_usage': {
        'type': 'gauge',
        'description': 'æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡',
        'labels': ['pool_name']
    },

    # ç¼“å­˜æŒ‡æ ‡
    'cache_hit_rate': {
        'type': 'gauge',
        'description': 'ç¼“å­˜å‘½ä¸­ç‡',
        'labels': ['cache_type', 'cache_name']
    },
    'cache_memory_usage_bytes': {
        'type': 'gauge',
        'description': 'ç¼“å­˜å†…å­˜ä½¿ç”¨é‡',
        'labels': ['cache_type']
    },

    # ä¸šåŠ¡æŒ‡æ ‡
    'active_users_total': {
        'type': 'gauge',
        'description': 'æ´»è·ƒç”¨æˆ·æ•°',
        'labels': ['time_window']
    },
    'stock_data_updates_total': {
        'type': 'counter',
        'description': 'è‚¡ç¥¨æ•°æ®æ›´æ–°æ¬¡æ•°',
        'labels': ['data_source', 'symbol']
    },
    'websocket_connections_total': {
        'type': 'gauge',
        'description': 'WebSocketè¿æ¥æ•°',
        'labels': ['connection_type']
    }
}
```

### 6.2 å‘Šè­¦è§„åˆ™å®šä¹‰
```yaml
# alert_rules.yml æ‰©å±•
groups:
  - name: application.rules
    rules:
      # APIæ€§èƒ½å‘Šè­¦
      - alert: HighAPILatency
        expr: histogram_quantile(0.95, api_request_duration_seconds_bucket) > 2
        for: 5m
        labels:
          severity: warning
          category: performance
        annotations:
          summary: "APIå“åº”æ—¶é—´è¿‡é«˜"
          description: "95%åˆ†ä½æ•°å“åº”æ—¶é—´è¶…è¿‡2ç§’"

      - alert: HighAPIErrorRate
        expr: rate(api_request_total{status_code=~"5.."}[5m]) / rate(api_request_total[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
          category: availability
        annotations:
          summary: "APIé”™è¯¯ç‡è¿‡é«˜"
          description: "5åˆ†é’Ÿå†…APIé”™è¯¯ç‡è¶…è¿‡5%"

      # æ•°æ®åº“æ€§èƒ½å‘Šè­¦
      - alert: SlowDatabaseQueries
        expr: histogram_quantile(0.95, db_query_duration_seconds_bucket) > 5
        for: 3m
        labels:
          severity: warning
          category: database
        annotations:
          summary: "æ•°æ®åº“æŸ¥è¯¢ç¼“æ…¢"
          description: "95%åˆ†ä½æ•°æŸ¥è¯¢æ—¶é—´è¶…è¿‡5ç§’"

      # ç¼“å­˜æ€§èƒ½å‘Šè­¦
      - alert: LowCacheHitRate
        expr: cache_hit_rate < 0.8
        for: 10m
        labels:
          severity: warning
          category: cache
        annotations:
          summary: "ç¼“å­˜å‘½ä¸­ç‡ä½"
          description: "ç¼“å­˜å‘½ä¸­ç‡ä½äº80%"

      # ä¸šåŠ¡æŒ‡æ ‡å‘Šè­¦
      - alert: DataSourceUnavailable
        expr: up{job="data-source-monitor"} == 0
        for: 1m
        labels:
          severity: critical
          category: business
        annotations:
          summary: "æ•°æ®æºä¸å¯ç”¨"
          description: "å…³é”®æ•°æ®æºè¿æ¥å¤±è´¥"
```

## 7. æˆåŠŸæŒ‡æ ‡å’ŒéªŒæ”¶æ ‡å‡†

### 7.1 æŠ€æœ¯æŒ‡æ ‡
- **ç›‘æ§è¦†ç›–ç‡**: è¾¾åˆ°95%ä»¥ä¸Šçš„å…³é”®æŒ‡æ ‡è¦†ç›–
- **å‘Šè­¦å‡†ç¡®ç‡**: è¯¯æŠ¥ç‡æ§åˆ¶åœ¨5%ä»¥ä¸‹
- **å¼‚å¸¸æ£€æµ‹ç²¾åº¦**: å‡†ç¡®ç‡è¾¾åˆ°90%ä»¥ä¸Š
- **è‡ªåŠ¨æ¢å¤æˆåŠŸç‡**: 80%ä»¥ä¸Šçš„å¸¸è§æ•…éšœè‡ªåŠ¨æ¢å¤
- **ç›‘æ§ç³»ç»Ÿå¯ç”¨æ€§**: 99.9%ä»¥ä¸Š

### 7.2 æ€§èƒ½æŒ‡æ ‡
- **å‘Šè­¦å“åº”æ—¶é—´**: å¹³å‡30ç§’å†…å‘å‡ºå‘Šè­¦
- **æ•°æ®æ”¶é›†å»¶è¿Ÿ**: æŒ‡æ ‡æ”¶é›†å»¶è¿Ÿå°äº10ç§’
- **æŸ¥è¯¢å“åº”æ—¶é—´**: ç›‘æ§æŸ¥è¯¢å“åº”æ—¶é—´å°äº2ç§’
- **å­˜å‚¨æ•ˆç‡**: ç›‘æ§æ•°æ®å‹ç¼©ç‡è¾¾åˆ°70%ä»¥ä¸Š

### 7.3 ä¸šåŠ¡æŒ‡æ ‡
- **æ•…éšœå‘ç°æ—¶é—´**: MTTD (Mean Time To Detection) < 2åˆ†é’Ÿ
- **æ•…éšœæ¢å¤æ—¶é—´**: MTTR (Mean Time To Recovery) < 15åˆ†é’Ÿ
- **è¿ç»´æ•ˆç‡æå‡**: äººå·¥å¹²é¢„å‡å°‘60%ä»¥ä¸Š
- **ç³»ç»Ÿç¨³å®šæ€§**: å¯ç”¨æ€§æå‡åˆ°99.95%ä»¥ä¸Š

## 8. é£é™©è¯„ä¼°å’Œç¼“è§£ç­–ç•¥

### 8.1 æŠ€æœ¯é£é™©
| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£ç­–ç•¥ |
|------|------|------|----------|
| ç›‘æ§ç³»ç»Ÿæ€§èƒ½å½±å“ | ä¸­ | ä¸­ | å¼‚æ­¥å¤„ç†ã€é‡‡æ ·ç­–ç•¥ã€èµ„æºé™åˆ¶ |
| æ•°æ®å­˜å‚¨æˆæœ¬å¢åŠ  | ä¸­ | é«˜ | æ•°æ®å‹ç¼©ã€åˆ†å±‚å­˜å‚¨ã€è‡ªåŠ¨æ¸…ç† |
| å‘Šè­¦é£æš´ | é«˜ | ä¸­ | å‘Šè­¦èšåˆã€é™æµæœºåˆ¶ã€æ™ºèƒ½å»é‡ |
| è¯¯æŠ¥ç‡è¿‡é«˜ | ä¸­ | ä¸­ | åŠ¨æ€é˜ˆå€¼ã€æœºå™¨å­¦ä¹ ä¼˜åŒ– |

### 8.2 è¿ç»´é£é™©
| é£é™© | å½±å“ | æ¦‚ç‡ | ç¼“è§£ç­–ç•¥ |
|------|------|------|----------|
| ç›‘æ§ç³»ç»Ÿæ•…éšœ | é«˜ | ä½ | é«˜å¯ç”¨éƒ¨ç½²ã€å¤‡ä»½ç›‘æ§ |
| é…ç½®é”™è¯¯ | ä¸­ | ä¸­ | é…ç½®éªŒè¯ã€ç‰ˆæœ¬æ§åˆ¶ã€å›æ»šæœºåˆ¶ |
| äººå‘˜æŠ€èƒ½ä¸è¶³ | ä¸­ | ä¸­ | åŸ¹è®­è®¡åˆ’ã€æ–‡æ¡£å®Œå–„ã€é€æ­¥è¿ç§» |

## 9. åç»­ä¼˜åŒ–æ–¹å‘

### 9.1 çŸ­æœŸä¼˜åŒ–ï¼ˆ3ä¸ªæœˆå†…ï¼‰
- åŸºäºç”¨æˆ·åé¦ˆä¼˜åŒ–å‘Šè­¦ç­–ç•¥
- å®Œå–„å¼‚å¸¸æ£€æµ‹ç®—æ³•
- å¢åŠ æ›´å¤šä¸šåŠ¡æŒ‡æ ‡
- ä¼˜åŒ–ç›‘æ§ç³»ç»Ÿæ€§èƒ½

### 9.2 ä¸­æœŸä¼˜åŒ–ï¼ˆ6ä¸ªæœˆå†…ï¼‰
- é›†æˆAIOpsèƒ½åŠ›
- å®ç°é¢„æµ‹æ€§ç»´æŠ¤
- å¢åŠ ç§»åŠ¨ç«¯ç›‘æ§åº”ç”¨
- å®Œå–„ç›‘æ§æ•°æ®åˆ†æ

### 9.3 é•¿æœŸä¼˜åŒ–ï¼ˆ1å¹´å†…ï¼‰
- æ„å»ºæ™ºèƒ½è¿ç»´å¹³å°
- å®ç°å…¨é“¾è·¯ç›‘æ§
- é›†æˆä¸šåŠ¡ç›‘æ§
- å»ºç«‹ç›‘æ§æ ‡å‡†å’Œæœ€ä½³å®è·µ

---

## é™„å½•

### A. ç›¸å…³æ–‡æ¡£é“¾æ¥
- [Prometheusé…ç½®æ–‡æ¡£](./backend/config/prometheus.yml)
- [Grafanaä»ªè¡¨æ¿é…ç½®](./backend/config/grafana-dashboard.json)
- [å‘Šè­¦è§„åˆ™é…ç½®](./backend/config/alert-rules.yml)
- [ç›‘æ§éƒ¨ç½²è„šæœ¬](./backend/scripts/deploy_monitoring.py)

### B. å‚è€ƒèµ„æ–™
- [Prometheusæœ€ä½³å®è·µ](https://prometheus.io/docs/practices/)
- [Grafanaä»ªè¡¨æ¿è®¾è®¡æŒ‡å—](https://grafana.com/docs/grafana/latest/best-practices/)
- [SREç›‘æ§ç­–ç•¥](https://sre.google/sre-book/monitoring-distributed-systems/)
- [AIOpså®è·µæŒ‡å—](https://www.aiops.org/best-practices/)

---

*æœ¬è®¾è®¡æ–‡æ¡£å°†æ ¹æ®å®æ–½è¿‡ç¨‹ä¸­çš„åé¦ˆå’Œéœ€æ±‚å˜åŒ–æŒç»­æ›´æ–°ä¼˜åŒ–ã€‚*
